{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sympy as sp\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sympy import Matrix, init_printing\n",
    "\n",
    "import qiskit\n",
    "from qiskit import *\n",
    "\n",
    "# Representing Data\n",
    "from qiskit.providers.aer import QasmSimulator, StatevectorSimulator, UnitarySimulator\n",
    "from qiskit.tools.visualization import plot_histogram, plot_state_city, plot_bloch_multivector\n",
    "\n",
    "# Monitor Job on Real Machine\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "\n",
    "from functools import reduce # perform sucessive tensor product\n",
    "\n",
    "# Calculating cost\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Generating random unitary matrix\n",
    "from scipy.stats import unitary_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem\n",
    "\n",
    "Implement a circuit which returns |00> and |11> with equal probability.\n",
    "\n",
    "Requirements :\n",
    "\n",
    "- Circuit should consist only of CNOTs, RXs and RYs. \n",
    "\n",
    "- Start from all parameters in parametric gates being equal to 0 or randomly chosen. \n",
    "\n",
    "- You should find the right set of parameters using gradient descent (you might use more advanced optimization methods if you like). \n",
    "\n",
    "- Simulations must be done with sampling - i.e. limited number of measurements per iteration and noise. \n",
    "\n",
    "- Compare the results for different numbers of measurements: 1, 10, 100, 1000. \n",
    "\n",
    "Bonus question:\n",
    "\n",
    "- How to make sure you produce state $|00\\rangle +|11 \\rangle$ and not $|00\\rangle - |11\\rangle$ ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpful Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices\n",
    "I = np.array([[1, 0], [0, 1]])\n",
    "X = np.array([[0, 1], [1, 0]])\n",
    "Y = np.array([[0, -1j], [1j, 0]])\n",
    "Z = np.array([[1, 0], [0, -1]])\n",
    "H = 1/np.sqrt(2)*np.array([[1, 1], [1, -1]])\n",
    "\n",
    "# Eigenvectors of Pauli Matrices\n",
    "zero = np.array([[1], [0]]) # Z plus basis state\n",
    "one = np.array([[0], [1]]) # Z plus basis state\n",
    "\n",
    "plus = np.array([[1], [1]])/np.sqrt(2) # X plus basis state\n",
    "minus = np.array([[1], [-1]])/np.sqrt(2) # X minus basis state\n",
    "\n",
    "up = np.array([[1], [1j]])/np.sqrt(2) # Y plus basis state\n",
    "down = np.array([[1], [-1j]])/np.sqrt(2) # Y plus basis state\n",
    "\n",
    "# Bell States\n",
    "B00 = np.array([[1], [0], [0], [1]])/np.sqrt(2) # Bell of 00\n",
    "B01 = np.array([[1], [0], [0], [-1]])/np.sqrt(2) # Bell of 01\n",
    "B10 = np.array([[0], [1], [1], [0]])/np.sqrt(2) # Bell of 10\n",
    "B11 = np.array([[0], [-1], [1], [0]])/np.sqrt(2) # Bell of 11\n",
    "\n",
    "# Rn Matrix Function\n",
    "Rx = lambda theta: np.array([[np.cos(theta/2), -1j*np.sin(theta/2)], [-1j*np.sin(theta/2), np.cos(theta/2)]])\n",
    "Ry = lambda theta: np.array([[np.cos(theta/2), -np.sin(theta/2)], [np.sin(theta/2), np.cos(theta/2)]])\n",
    "Rz = lambda theta: np.array([[np.exp(-1j*theta/2), 0], [0, np.exp(1j*theta/2)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view(mat):\n",
    "    display(Matrix(mat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Unitary/StateVector Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function return the statevector or the unitary of an inputted circuit\n",
    "\n",
    "def get(circ, types = 'unitary'):\n",
    "    if types == 'statevector':\n",
    "        backend = BasicAer.get_backend('statevector_simulator')\n",
    "        out = execute(circ, backend).result().get_statevector()\n",
    "    else: \n",
    "        backend = BasicAer.get_backend('unitary_simulator')\n",
    "        out = execute(circ, backend).result().get_unitary()\n",
    "        \n",
    "    return display(Matrix(np.round(out, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_neural_net(ax, left, right, bottom, top, layer_sizes):\n",
    "    '''\n",
    "    Draw a neural network cartoon using matplotilb.\n",
    "    \n",
    "    :usage:\n",
    "        >>> fig = plt.figure(figsize=(12, 12))\n",
    "        >>> draw_neural_net(fig.gca(), .1, .9, .1, .9, [4, 7, 2])\n",
    "    \n",
    "    :parameters:\n",
    "        - ax : matplotlib.axes.AxesSubplot\n",
    "            The axes on which to plot the cartoon (get e.g. by plt.gca())\n",
    "        - left : float\n",
    "            The center of the leftmost node(s) will be placed here\n",
    "        - right : float\n",
    "            The center of the rightmost node(s) will be placed here\n",
    "        - bottom : float\n",
    "            The center of the bottommost node(s) will be placed here\n",
    "        - top : float\n",
    "            The center of the topmost node(s) will be placed here\n",
    "        - layer_sizes : list of int\n",
    "            List of layer sizes, including input and output dimensionality\n",
    "    '''\n",
    "    n_layers = len(layer_sizes)\n",
    "    v_spacing = (top - bottom)/float(max(layer_sizes))\n",
    "    h_spacing = (right - left)/float(len(layer_sizes) - 1)\n",
    "    # Nodes\n",
    "    for n, layer_size in enumerate(layer_sizes):\n",
    "        layer_top = v_spacing*(layer_size - 1)/2. + (top + bottom)/2.\n",
    "        for m in range(layer_size):\n",
    "            circle = plt.Circle((n*h_spacing + left, layer_top - m*v_spacing), v_spacing/4.,\n",
    "                                color='w', ec='k', zorder=4)\n",
    "            ax.add_artist(circle)\n",
    "    # Edges\n",
    "    for n, (layer_size_a, layer_size_b) in enumerate(zip(layer_sizes[:-1], layer_sizes[1:])):\n",
    "        layer_top_a = v_spacing*(layer_size_a - 1)/2. + (top + bottom)/2.\n",
    "        layer_top_b = v_spacing*(layer_size_b - 1)/2. + (top + bottom)/2.\n",
    "        for m in range(layer_size_a):\n",
    "            for o in range(layer_size_b):\n",
    "                line = plt.Line2D([n*h_spacing + left, (n + 1)*h_spacing + left],\n",
    "                                  [layer_top_a - m*v_spacing, layer_top_b - o*v_spacing], c='k')\n",
    "                ax.add_artist(line)\n",
    "                \n",
    "                \n",
    "# Draw neural network for this problem\n",
    "def draw_nn():\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    fig.text(0.15, 0.76, 'Input Layer', fontsize = 12)\n",
    "    fig.text(0.75, 0.76, 'Output Layer', fontsize = 12)\n",
    "\n",
    "    # Input Layer\n",
    "    fig.text(0.177, 0.65, 'x_0', fontsize = 16)\n",
    "    fig.text(0.177, 0.35, 'x_1', fontsize = 16)\n",
    "    \n",
    "    # Output Layer\n",
    "    fig.text(0.795, 0.65, 'y_0', fontsize = 16)\n",
    "    fig.text(0.795, 0.35, 'y_1', fontsize = 16)\n",
    "\n",
    "    ax = fig.gca()\n",
    "    ax.axis('off')\n",
    "    draw_neural_net(ax, .1, .9, .1, .9, [2, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gram-Schmidt Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_cofficient(v1, v2):\n",
    "    return numpy.dot(v2, v1) / numpy.dot(v1, v1)\n",
    "\n",
    "def multiply(cofficient, v):\n",
    "    return map((lambda x : x * cofficient), v)\n",
    "\n",
    "def proj(v1, v2):\n",
    "    return multiply(gs_cofficient(v1, v2) , v1)\n",
    "\n",
    "def gs(X):\n",
    "    Y = []\n",
    "    for i in range(len(X)):\n",
    "        temp_vec = X[i]\n",
    "        for inY in Y :\n",
    "            proj_vec = proj(inY, X[i])\n",
    "            #print \"i =\", i, \", projection vector =\", proj_vec\n",
    "            temp_vec = map(lambda x, y : x - y, temp_vec, proj_vec)\n",
    "            #print \"i =\", i, \", temporary vector =\", temp_vec\n",
    "        Y.append(temp_vec)\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1. Create a quantum circuit with Hamadamard and CX\n",
    "\n",
    "    2. Decompose Hadamard into R_X and R_Y using gate decomposition\n",
    "\n",
    "    3. Draw Neural Network graph\n",
    "\n",
    "    4. Create data to train/test\n",
    "\n",
    "    5. Initialized weights\n",
    "\n",
    "    6. Implement Forward Propagation\n",
    "\n",
    "    7. Define Cost function\n",
    "\n",
    "    8. Implement Backpropagation\n",
    "\n",
    "    9. Implement Gradient Descent to updates the weights in each layers\n",
    "    \n",
    "    10. Check that each layer is implemented correctly\n",
    "    \n",
    "    11. Train Model\n",
    "    \n",
    "    12. Evaluate Model\n",
    "    \n",
    "    13. Full Optimization Implementation\n",
    "    \n",
    "    14. Sampling on Quantum Circuit\n",
    "    \n",
    "\n",
    "Optional:\n",
    "\n",
    "    - Implement Adam Optimization\n",
    "    - Implement General Neural Network\n",
    "    - Implement Forward Prop with simulation\n",
    "    - Bonus question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Build Bell Circuit\n",
    "\n",
    "Create a quantum circuit with Hadamard and CX\n",
    "\n",
    "Typically, a circuit to create the $\\frac{1}{\\sqrt{2}}(|00\\rangle + |11\\rangle)$ looks like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Quantum Circuit with Hadamard and CX\n",
    "circ = QuantumCircuit(2)\n",
    "circ.h(0)\n",
    "circ.cx(0, 1)\n",
    "\n",
    "circ.draw('mpl')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of the four CBS for this circuit are the following\n",
    "\n",
    "Let matrix B represents the unitary of the circuit\n",
    "\n",
    "$$B |00\\rangle = \\frac{1}{\\sqrt{2}} (|00\\rangle + |11\\rangle)$$\n",
    "\n",
    "$$B |01\\rangle = \\frac{1}{\\sqrt{2}} (|00\\rangle - |11\\rangle)$$\n",
    "\n",
    "$$B |10\\rangle = \\frac{1}{\\sqrt{2}} (|01\\rangle + |10\\rangle)$$\n",
    "\n",
    "$$B |11\\rangle = \\frac{1}{\\sqrt{2}} (-|01\\rangle + |10\\rangle)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Hadamard Decomposition\n",
    "\n",
    "Decompose Hadamard into $R_X(\\phi)$ and $R_Y(\\theta)$ using gate decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hadamard\n",
    "\n",
    "$$H = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 & 1\\\\ 1 & -1  \\end{bmatrix}$$\n",
    "\n",
    "#### X-axis Rotation\n",
    "\n",
    "$$R_X( \\theta ) = \\begin{bmatrix} cos \\frac{\\theta}{2} & -i sin \\frac{\\theta}{2} \\\\ -i sin \\frac{\\theta}{2} & cos \\frac{\\theta}{2}  \\end{bmatrix}$$\n",
    "\n",
    "#### Y-axis Rotation\n",
    "\n",
    "$$R_Y( \\theta ) = \\begin{bmatrix} cos \\frac{\\theta}{2} & -sin \\frac{\\theta}{2} \\\\ sin \\frac{\\theta}{2} & cos \\frac{\\theta}{2}  \\end{bmatrix}$$\n",
    "\n",
    "The Hadamard decomposition is as followed:\n",
    "\n",
    "$$H = R_y(-\\frac{\\pi}{2})R_x(\\pi)$$\n",
    "\n",
    "Subsequently, the new circuit will looks like this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "# Implement a R_y, R_x circuit. Notice that the order is flipped\n",
    "circ = QuantumCircuit(2)\n",
    "circ.rx(np.pi, 0)\n",
    "circ.ry(-np.pi/2, 0)\n",
    "circ.cx(0, 1)\n",
    "\n",
    "circ.draw('mpl')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of the four CBS for this circuit are the following\n",
    "\n",
    "Let matrix M represents the unitary of the circuit\n",
    "\n",
    "$$M |00\\rangle = \\frac{1}{\\sqrt{2}} (|00\\rangle + |11\\rangle)$$\n",
    "\n",
    "$$M |01\\rangle = \\frac{1}{\\sqrt{2}} (|00\\rangle - |11\\rangle)$$\n",
    "\n",
    "$$M |10\\rangle = \\frac{1}{\\sqrt{2}} (|01\\rangle + |10\\rangle)$$\n",
    "\n",
    "$$M |11\\rangle = \\frac{1}{\\sqrt{2}} (-|01\\rangle + |10\\rangle)$$\n",
    "\n",
    "This is the same as the normal Bell states circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Draw Neural Network\n",
    "\n",
    "The neural network for this aims to mimic the $R_y(-\\frac{\\pi}{2})R_x(\\pi)$ matrix complex\n",
    "\n",
    "When plugging in the correct value, the $-i$ factors on the $R_x(\\phi)$ eventually dissapear as a global phase. \n",
    "\n",
    "Because of this, we can frame the $R_x(\\phi)$ in a simpler form\n",
    "\n",
    "$$R_y(\\theta)R_x(\\phi)(X) = \\begin{bmatrix} cos \\frac{\\theta}{2} & -sin \\frac{\\theta}{2} \\\\ sin \\frac{\\theta}{2} & cos \\frac{\\theta}{2}  \\end{bmatrix} \\begin{bmatrix} cos \\frac{\\phi}{2} & sin \\frac{\\phi}{2} \\\\ sin \\frac{\\phi}{2} & cos \\frac{\\phi}{2}  \\end{bmatrix} \\begin{pmatrix} x_0 \\\\ x_1 \\end{pmatrix}$$\n",
    "\n",
    "The middle two matrices can be reduced into sum and difference formula\n",
    "\n",
    "$$R_y(\\theta)R_x(\\phi)(X) = \\begin{bmatrix} cos\\frac{\\phi + \\theta}{2} & sin\\frac{\\phi - \\theta}{2} \\\\ sin\\frac{\\phi + \\theta}{2} & cos\\frac{\\phi - \\theta}{2}\\end{bmatrix} \\begin{pmatrix} x_0 \\\\ x_1 \\end{pmatrix}$$\n",
    "\n",
    "This neural network has one layers, each layers with two nodes, and each nodes with two weights. We can set the weight matrix $W$ as follow:\n",
    "\n",
    "$$W = \\begin{bmatrix} cos\\frac{\\phi + \\theta}{2} & sin\\frac{\\phi - \\theta}{2} \\\\ sin\\frac{\\phi + \\theta}{2} & cos\\frac{\\phi - \\theta}{2}\\end{bmatrix} = \\begin{bmatrix} \\alpha & \\beta \\\\ \\gamma & \\delta \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_nn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Each nodes in the hidden layer and the output layer contains two weights\n",
    "\n",
    "The square bracket index represents the layer the node is in.\n",
    "\n",
    "The curly bracket index represents the position of the node in its respective layer.\n",
    "\n",
    "###### Output Layer\n",
    "\n",
    "$$y_0 = W^{[1]\\{0\\}} \\cdot X$$\n",
    "\n",
    "Where $W^{[1]\\{0\\}} = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}$, $\\alpha$ and $\\beta$ are parameters\n",
    "\n",
    "From this, we can see that the output equals\n",
    "\n",
    "$$ y_0 = \\alpha x_0 + \\beta x_1 $$\n",
    "\n",
    "Also,\n",
    "\n",
    "$$y_1 = \\gamma x_0 + \\delta x_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create data\n",
    "\n",
    "There are two approachs to doing this: \n",
    "\n",
    "1. Create a small number of training examples so the algorithm intentionally overfits the data ( < 10 $(X, y)$ pairs)\n",
    "2. Create a large number of training examples so the algorithm can be more robust ( > 1000 $(X, y)$ pairs)\n",
    "\n",
    "Both approachs will be attempted and the better of the two will be chosen\n",
    "\n",
    "Steps to creating data:\n",
    "\n",
    "1. Randomize a 2-d real unit vectors, this is $X$ (for this purpose, ignore complex number)\n",
    "2. Using the known matrix, take the product of the two, this is $y$\n",
    "3. Repeat the process $n$ times as deemed necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Vector Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "```python\n",
    "M_correct = H\n",
    "\n",
    "### X-values\n",
    "\n",
    "# Create a random 2-d real vector\n",
    "x = np.random.rand(2, 1)\n",
    "\n",
    "# Normalize v\n",
    "x /= np.linalg.norm(x)\n",
    "\n",
    "### Y-values\n",
    "\n",
    "# Matrix Multiplication\n",
    "y = np.dot(M_correct, x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Vectors Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(M_correct, size = 500, train_split = 0.7, seed = 0):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Create two matrices of specified length consisting of 2-d vectors representing\n",
    "    a train and a test examples\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    M_correct: ndarray\n",
    "        Matrix that transform the input to the correct output\n",
    "    size: int\n",
    "        Number of examples (train & test) in the dataset\n",
    "    train_split: float\n",
    "        Proportion of the train data to the total dataset\n",
    "        \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_train: ndarray\n",
    "        Matrix containing the x-values of all the training examples\n",
    "    y_train: ndarray\n",
    "        Matrix containing the y-values of all the training examples\n",
    "    X_test: ndarray\n",
    "        Matrix containing the x-values of all the testing examples\n",
    "    y_test: ndarray\n",
    "        Matrix containing the y-values of all the testing examples\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Manage defaults for 'size'\n",
    "    if size == 'small':\n",
    "        size = 10\n",
    "    elif size == 'large':\n",
    "        size = 1000\n",
    "    \n",
    "    ### X-values\n",
    "    \n",
    "    # Create a random matrix of 2-d real vectors as columns\n",
    "    X = np.random.rand (2, size)\n",
    "    \n",
    "    # Normalize v by column axix\n",
    "    X /= np.linalg.norm(X, axis = 0)\n",
    "    \n",
    "    # Check for normalization\n",
    "    assert np.round(np.sum(np.power(X, 2)), 10) == size, 'X is not normalized'\n",
    "    \n",
    "    # Check for correct shape\n",
    "    assert X.shape == (2, size), 'the shape of X is not correct'\n",
    "    \n",
    "    ### Y-values\n",
    "    \n",
    "    # Matrix Multiplication\n",
    "    y = np.dot(M_correct, X)\n",
    "    \n",
    "    # Check for unitary\n",
    "    assert np.round(np.sum(np.dot(M_correct, M_correct.conj().T)), 10) == 2, 'M_correct is not unitary'\n",
    "    \n",
    "    # Check for correct shape\n",
    "    assert y.shape == (2, size), 'the shape of y is not correct'\n",
    "    \n",
    "    # Splitting the matrix into its corresponding groups\n",
    "    \n",
    "    X_train = X[:, :int(size*train_split)]\n",
    "    y_train = y[:, :int(size*train_split)]\n",
    "    \n",
    "    X_test = X[:, int(size*train_split):]\n",
    "    y_test = y[:, int(size*train_split):]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Initialization\n",
    "The $W$ matrix will be initialized to all zeros or randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(init_type = 'random', dim = (2, 2), seed = 0):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Initialize the W matrix of a specified size to all zeros or randomly\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    init_type: str\n",
    "        Specify whether W will be initialized to all zeros or randomly\n",
    "    shape: tuple\n",
    "        Specify shape of W\n",
    "    seed: int\n",
    "        Used for pseudo-randomly generate matrix\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    W: ndarray\n",
    "        Initialized W matrix (all zeros or pseudo-random)\n",
    "        \n",
    "    \"\"\"\n",
    "      \n",
    "    # Zero Initialization\n",
    "    if init_type == 'zeros':\n",
    "        \n",
    "        W = np.zeros(dim)  \n",
    "        \n",
    "    # Random Initialization\n",
    "    else:\n",
    "        # Keep the values consistent\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        W = np.random.rand(*dim)\n",
    "\n",
    "    # Check for W shape\n",
    "    assert W.shape == dim, 'shape of W is not correct'\n",
    "        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Forward Propagation\n",
    "\n",
    "Forward propagation passes the input into the neural network to predict an output value\n",
    "\n",
    "$$\\hat{y} = \\underbrace{\\begin{bmatrix} \\alpha & \\beta \\\\ \\gamma & \\delta \\end{bmatrix}}_{W} \\begin{pmatrix} x_0 \\\\ x_1 \\end{pmatrix}$$\n",
    "\n",
    "To run multiple training examples at the same time (stochastic), put the training examples into a matrix a multiply it with the weight matrix. The index of training examples will be represented by the superscript inside the parentheses.\n",
    "\n",
    "$$W(X) \\ = \\ W \\begin{pmatrix} x_0^{(0)} & x_0^{(1)} ... & \\ x_0^{(n)} \\\\ x_1^{(0)} & x_1^{(1)} ... & \\ x_1^{(n)} \\end{pmatrix} \\ = \\ \\begin{pmatrix} \\hat{y}^{(0)} & \\hat{y}^{(1)} & ... & \\hat{y}^{(n)}\\end{pmatrix}$$\n",
    "\n",
    "There are two ways of running forward propagation:\n",
    "\n",
    "1. Simulate the circuit using 'qasm_simulator' \n",
    "\n",
    "    - This is less practical because it requires taking the square root of the count probability to get back to the weights.\n",
    "    \n",
    "    \n",
    "2. Calculate the output value using directly using linear algebra\n",
    "\n",
    "    - Forward prop will be calculated using this method at the moment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(W, X, path = None):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Perform the forward propagation step\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    W: ndarray\n",
    "        Matrix of the weights in used\n",
    "    X: ndarray \n",
    "        Matrix of x-values\n",
    "    path: str\n",
    "        Specify whether the forward prop is done classically or using a quantum simulator\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y_hat: ndarray\n",
    "        Predicted value to be used for back-prop\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Simulate using 'qasm simulator'\n",
    "    if path == 'sim':\n",
    "        pass\n",
    "    \n",
    "    # Calculate using linear algebra\n",
    "    else:\n",
    "        y_hat = np.dot(W, X)\n",
    "        \n",
    "    # Make sure the shape is consistent\n",
    "    assert X.shape == y_hat.shape, 'Shape is not consistent'\n",
    "    \n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Define Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a regression problem, we will calculate the cost using Half Mean Squared Error (MSE), which we will define as\n",
    "\n",
    "$$J(W) = \\frac{1}{2N} \\sum^{N}_{i=1} \\underbrace{||y_i - \\hat{y}_i||^2}_{L(W)}$$\n",
    "\n",
    "where $N$ is the number of training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y, y_hat):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Compute half mean-squared error cost\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: ndarray\n",
    "        The true y value generated from a preset matrix (see step 4: Create Data)\n",
    "    y_hat: ndarray\n",
    "        The predicted y value from a learned set of weights (see step 6: Forward Propagation)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    J: float\n",
    "        Scalar matrix to indicate the overall performance of the current set of weights\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # N is number of training examples\n",
    "    N = y.shape[1]\n",
    "    \n",
    "    # Compute cost function\n",
    "    J = 1/(2*N) * np.sum(np.linalg.norm(y - y_hat)**2)\n",
    "    \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding the matrices from above (only caring about the subscript, we have)\n",
    "\n",
    "$$\\hat{y} = \\begin{bmatrix} cos\\frac{\\phi + \\theta}{2} & sin\\frac{\\phi - \\theta}{2} \\\\ sin\\frac{\\phi + \\theta}{2} & cos\\frac{\\phi - \\theta}{2}\\end{bmatrix} \\begin{pmatrix} x_0 \\\\ x_1 \\end{pmatrix} = \\underbrace{\\begin{bmatrix} \\alpha & \\beta \\\\ \\gamma & \\delta \\end{bmatrix}}_{W} \\begin{pmatrix} x_0 \\\\ x_1 \\end{pmatrix} = \\begin{pmatrix} \\alpha x_0 + \\beta x_1 \\\\ \\gamma x_0 + \\delta x_1 \\end{pmatrix}$$\n",
    "\n",
    "To find the local minimum, update the parameters opposite of the direction of steepest descent. Backpropagation calculates derivative of the cost function with respect to each of the weights.\n",
    "\n",
    "From above\n",
    "\n",
    "$$J(W) = \\frac{1}{2N} \\sum^{N}_{i=1} \\underbrace{||y_i - \\hat{y}_i||^2}_{L(W)}$$\n",
    "\n",
    "The cost function can be written as "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(W) = \\frac{1}{2N} \\sum^{N}_{i=1} \\begin{Vmatrix} y_0 - (\\alpha x_0 + \\beta x_1) \\\\ y_1 - (\\gamma x_0 + \\delta x_1) \\end{Vmatrix}^2 = \\frac{1}{2N} \\sum^{N}_{i=1} \\overbrace{{\\underbrace{[(\\alpha x_0 + \\beta x_1 - y_0]}_{L_0}}^2 + {\\underbrace{[\\gamma x_0 + \\delta x_1 - y_1]}_{L_1}}^2}^{L(W)}$$\n",
    "\n",
    "In this case, the loss function $L(W)$ can be expressed as the sum of $L_0$ and $L_1$\n",
    "\n",
    "$$L(W) = (L_0)^2 + (L_1)^2$$\n",
    "\n",
    "Taking partial derivative with respect to a general weight ($w$)\n",
    "\n",
    "$$\\frac{\\partial}{\\partial w}J(W) = \\frac{1}{2N} \\sum^{N}_{i=1} \\frac{\\partial}{\\partial w} L(W) = \\frac{1}{2N} \\sum^{N}_{i=1} \\frac{\\partial}{\\partial w} [(L_0)^2 + (L_1)^2]$$ \n",
    "\n",
    "A $2$ can be factored out after taking the derivative of $(L_0)^2$ and $(L_1)^2$\n",
    "\n",
    "$$= \\frac{1}{N} \\sum^{N}_{i=1} \\begin{pmatrix} L_0 \\frac{\\partial L_0}{\\partial w} + L_1 \\frac{\\partial L_1}{\\partial w} \\end{pmatrix}$$ \n",
    "\n",
    "Put everything together, the cost function derivatives with respect to $\\alpha, \\beta, \\gamma$ and $\\delta$ are\n",
    "\n",
    "###### Alpha\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\alpha} = \\frac{1}{N} \\sum^{N}_{i=1} L_0 x_0$$\n",
    "\n",
    "###### Beta\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\beta} = \\frac{1}{N} \\sum^{N}_{i=1} L_0 x_1$$\n",
    "\n",
    "###### Gamma\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\gamma} = \\frac{1}{N} \\sum^{N}_{i=1} L_1 x_0$$\n",
    "\n",
    "###### Delta\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\delta} = \\frac{1}{N} \\sum^{N}_{i=1} L_1 x_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement these four calculations in code with multiple training examples, \n",
    "\n",
    "1. Calculate the difference between all the $y$'s and $\\hat{y}$'s\n",
    "\n",
    "$$\\text{diff} = \\begin{pmatrix} y_0 - (\\alpha x_0 + \\beta x_1) \\\\ y_1 - (\\gamma x_0 + \\delta x_1) \\end{pmatrix} = y - \\hat{y} = \\begin{pmatrix} L_0 \\\\ L_1 \\end{pmatrix}$$\n",
    "\n",
    "2. Elongate this 'diff' matrix & the $X$ matrix as follow and perform element-wise multiplication\n",
    "\n",
    "$$\\text{elem_prod} = \\begin{bmatrix} \\begin{pmatrix} L_0 \\\\ L_0 \\end{pmatrix} \\\\ \\begin{pmatrix} L_1 \\\\ L_1  \\end{pmatrix} \\end{bmatrix} * \\begin{bmatrix} \\begin{pmatrix} x_0 \\\\ x_1 \\end{pmatrix} \\\\ \\begin{pmatrix} x_0 \\\\ x_1 \\end{pmatrix} \\end{bmatrix} = \\begin{pmatrix} L_0 x_0 \\\\ L_0 x_1 \\\\ L_1 x_0 \\\\ L_1 x_1\\end{pmatrix}$$\n",
    "\n",
    "3. Recall that each each $x$ and $L$ contains multiple training examples. \n",
    "\n",
    "Take the average of the row of the matrix and unpack it to the appropriate derivative variable. Note that $\\frac{\\partial J}{\\partial w}$ turns into $\\partial w$\n",
    "\n",
    "$$J = \\frac{1}{N} \\begin{pmatrix} \\sum^{N}_{i=1} L_0 x_0 \\\\ \\sum^{N}_{i=1} L_0 x_1 \\\\ \\sum^{N}_{i=1} L_1 x_0 \\\\ \\sum^{N}_{i=1} L_1 x_1\\end{pmatrix} = \\begin{pmatrix} \\partial \\alpha \\\\ \\partial \\beta \\\\ \\partial \\gamma \\\\ \\partial \\delta \\end{pmatrix}$$\n",
    "\n",
    "4. Finally reshape the weights into a square matrix for the gradient descent step\n",
    "\n",
    "$$\\begin{pmatrix} \\partial \\alpha \\\\ \\partial \\beta \\\\ \\partial \\gamma \\\\ \\partial \\delta \\end{pmatrix} \\longrightarrow \\begin{bmatrix} \\partial \\alpha & \\partial \\beta \\\\ \\partial \\gamma & \\partial \\delta \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(y, y_hat, X):\n",
    "        \n",
    "    \"\"\"\n",
    "    Calculate derivatives of the cost function (see step 7: Define Cost Function)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y: ndarray\n",
    "        The true y value generated from a preset matrix (see step 4: Create Data)\n",
    "    y_hat: ndarray\n",
    "        The predicted y value from a learned set of weights (see step 6: Forward Propagation)\n",
    "    X: ndarray\n",
    "        The X value used to generate the 'y' value\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dJ: ndarray\n",
    "        Matrix of partial derivatives with respect to each of the weights\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    # Extract number of examples\n",
    "    N = y_hat.shape[1]\n",
    "\n",
    "    # Reshape X\n",
    "    X = np.reshape(X, (2, N))\n",
    "\n",
    "    # Calculate the y - y_hat\n",
    "    diff = y - y_hat\n",
    "\n",
    "    # Elongate the diff array with repeating elements\n",
    "    diff = np.repeat(diff, 2, axis = 0)\n",
    "\n",
    "    # Reshape\n",
    "    diff = np.reshape(diff, (4, N))\n",
    "\n",
    "    # Elongate the x array with alternating elements\n",
    "    X = np.vstack((X, X))\n",
    "\n",
    "    # Check to see if both array has the same shape\n",
    "\n",
    "    assert X.shape == diff.shape, 'Shape is not consistent'\n",
    "\n",
    "    # Element-wise multiplication between the diff matrix and the x matrix\n",
    "    elem_prod = diff * X\n",
    "\n",
    "    # Average the row of the matrix\n",
    "    dJ = (1/N) * np.sum(elem_prod, axis = 1)\n",
    "\n",
    "    # Reshape\n",
    "\n",
    "    dJ = np.reshape(dJ, (4, 1))\n",
    "\n",
    "    # Check J shape\n",
    "    assert dJ.shape == (4,1), 'Shape is not correct'\n",
    "\n",
    "    # Reshape J into a matrix\n",
    "    dJ = dJ.reshape(2, 2)\n",
    "\n",
    "    assert dJ.shape == (2, 2), 'Shape is not square'\n",
    "\n",
    "    return dJ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Gradient Descent (GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general weight update with learning rate $\\rho$ is as follow\n",
    "\n",
    "$$w := w - \\rho \\frac{\\partial J}{\\partial w}$$\n",
    "\n",
    "$\\rho$ is defaulted as 0.001. However, once the implementation is sucessful, $\\rho$ can be varied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(weights, grad, learning_rate = 0.001):\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Update the weights using gradients calculated from step 8: Backpropagation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    weights: ndarray\n",
    "        Matrix of weights used for training\n",
    "    grad: ndarray\n",
    "        Matrix of gradients calculated from step 8: Backpropagation\n",
    "    learning_rate: float\n",
    "        Determines the speed step size of the weights update\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    new_weights: ndarray\n",
    "        Matrix of weights after updated\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    new_weights = weights - learning_rate * grad\n",
    "    \n",
    "    assert weights.shape == new_weights.shape\n",
    "    \n",
    "    assert new_weights.shape == (2, 2)\n",
    "    \n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Check for Correct Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checklist:\n",
    "\n",
    "    1. Create train/test data\n",
    "    2. Initialization\n",
    "    3. Forward Propagation\n",
    "    4. Define Cost Function\n",
    "    5. Back Propagation\n",
    "    6. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Create train/test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the following:\n",
    "\n",
    "1. Correct shape for both train and test set from 'size' and 'train_split'\n",
    "2. The y matrix is the output of the X matrix with the M_correct\n",
    "\n",
    "Run the code below to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for i in range(10_000):\n",
    "    \n",
    "    # Size of dataset\n",
    "    n = np.random.randint(1, 10_000)\n",
    "    \n",
    "    # Train split\n",
    "    split = np.random.uniform()\n",
    "    \n",
    "    # Random unitary matrix\n",
    "    M = unitary_group.rvs(2)\n",
    "        \n",
    "    X_train, y_train, X_test, y_test = create_data(M, size = n, train_split = split)\n",
    "    \n",
    "    # Same shape for training pairs\n",
    "    assert X_train.shape == y_train.shape\n",
    "    \n",
    "    # Same shape for testing pairs\n",
    "    assert X_test.shape == y_test.shape\n",
    "    \n",
    "    # Correct no. of examples from 'size' and 'train_split'\n",
    "    assert X_train.shape[1] == int(n * split)\n",
    "    \n",
    "    # Everything adds up to 'size'\n",
    "    assert X_train.shape[1] + X_test.shape[1] == n\n",
    "    \n",
    "    # Check the output y is correct\n",
    "    assert np.round(np.sum(np.dot(M, X_train) - y_train), 10) == 0\n",
    "    \n",
    "    assert np.round(np.sum(np.dot(M, X_test) - y_test), 10) == 0\n",
    "    \n",
    "print('Everything is good')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for this is simple enough to just be inspect by eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 3. Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking by running through random examples\n",
    "\n",
    "Run the code below to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "for i in range(10_000):\n",
    "\n",
    "    # Random weight matrix\n",
    "    W = np.random.rand(2, 2)\n",
    "\n",
    "    # Random X matrix\n",
    "    n = np.random.randint(1, 10_000)\n",
    "    X = np.random.rand(2, n)\n",
    "\n",
    "    # Run function\n",
    "    forward_prop(W, X, path = None)\n",
    "\n",
    "print('Everything is good')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. Define Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be checked by comparing it to the 'mean_squared_error' within scikit learn\n",
    "\n",
    "Run the code below to check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for i in range(10_000):\n",
    "    \n",
    "    np.random.seed(i)\n",
    "\n",
    "    n = np.random.randint(1, 10_000)\n",
    "    y = np.random.rand(2, n)\n",
    "    y_hat = np.random.rand(2, n)\n",
    "\n",
    "    assert np.round(mean_squared_error(y, y_hat) - cost(y, y_hat), 15) == 0\n",
    "     \n",
    "print('Everything is good')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 10_000 random examples, it can be seen that the two function is equivalent, when the first dimension of the matrix is 2. However, when this dimension is not 2, the difference is drastic. In the end, the cost(y, y_hat) function will be used because it is significantly faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. Back Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the following:\n",
    "\n",
    "1. Manually check if all the steps is implemented correctly\n",
    "\n",
    "2. Check that back_prop(y, y, X) = 0, 0, 0, 0\n",
    "\n",
    "3. Perform gradient checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This is the first step. The code preceding the assert statement is a step-by-step break down (non-vectorized) implementation of the back-prop module. It is manually check for small matrix size. The result is the same for the first 100_000 examples\n",
    "\n",
    "```python\n",
    "for i in range(100_000):\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    \n",
    "    n = np.random.randint(1, 10_000)\n",
    "\n",
    "    X = np.random.rand(2, n)\n",
    "\n",
    "    x_0 = X[0]\n",
    "    x_0 = np.reshape(x_0, (1, n))\n",
    "\n",
    "    x_1 = X[1]\n",
    "    x_1 = np.reshape(x_1, (1, n))\n",
    "\n",
    "    np.random.seed(i+1)\n",
    "\n",
    "    y = np.random.rand(2, n)\n",
    "\n",
    "    np.random.seed(i+2)\n",
    "\n",
    "    y_hat = np.random.rand(2, n)\n",
    "\n",
    "    diff = y - y_hat\n",
    "\n",
    "    L_0 = diff[0]\n",
    "    L_0 = np.reshape(L_0, (1, n))\n",
    "\n",
    "    L_1 = diff[1]\n",
    "    L_1 = np.reshape(L_1, (1, n))\n",
    "\n",
    "    # Alpha\n",
    "    d_alpha = (1/n) * np.sum(L_0 * x_0)\n",
    "\n",
    "    # Beta\n",
    "    d_beta = (1/n) * np.sum(L_0 * x_1)\n",
    "\n",
    "    # Gamma\n",
    "    d_gamma = (1/n) * np.sum(L_1 * x_0)\n",
    "\n",
    "    # Delta\n",
    "    d_delta = (1/n) * np.sum(L_1 * x_1)\n",
    "\n",
    "    dJ = np.array([[d_alpha, d_beta], [d_gamma, d_delta]])\n",
    "    \n",
    "    assert np.sum(dJ - back_prop(y, y_hat, X)) == 0, 'not equal'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check that back_prop(y, y, X) = 0, 0, 0, 0\n",
    "\n",
    "This is correct for 10_000 random examples\n",
    "\n",
    "```python\n",
    "for i in range(10_000):\n",
    "    n = np.random.randint(1, 10_000)\n",
    "    X_train, y_train, X_test, y_test = create_data(H, size = n, train_split = 1, seed = i)\n",
    "\n",
    "    assert np.all(back_prop(y_train, y_train, X_train) == np.zeros((2, 2)))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Grad Check\n",
    "\n",
    "Run code below to compare 'back_prop' function and numerically calculated gradient\n",
    "\n",
    "The numerical derivative will be calculated using a two-sided derivative\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\lim_{\\varepsilon \\to 0} \\frac{J(w + \\varepsilon) - J(w - \\varepsilon)}{2 \\varepsilon}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "for i in range(10_000):\n",
    "    n = np.random.randint(1, 10_000)\n",
    "\n",
    "    X_train, y_train, _ , _   = create_data(H, size = n, train_split=1, seed = i)\n",
    "\n",
    "    W = initialize('random', dim = (2, 2), seed = i)\n",
    "\n",
    "    y_hat = forward_prop(W, X_train)\n",
    "\n",
    "    grad = back_prop(y_train, y_hat, X_train)\n",
    "\n",
    "    epsilon = 1e-7\n",
    "\n",
    "    # Create epsilon Matrix\n",
    "    ep_alpha = np.array([[epsilon, 0], [0, 0]])\n",
    "\n",
    "    ep_beta = np.array([[0, epsilon], [0, 0]])\n",
    "\n",
    "    ep_gamma = np.array([[0, 0], [epsilon, 0]])\n",
    "\n",
    "    ep_delta = np.array([[0, 0], [0, epsilon]])\n",
    "\n",
    "    # Alpha\n",
    "\n",
    "    # + epsilon on the alpha term\n",
    "    alpha_plus = W + ep_alpha\n",
    "    alpha_minus = W - ep_alpha\n",
    "\n",
    "    # Forward Prop\n",
    "    numerator = cost(y_train, forward_prop(alpha_plus, X_train)) - cost(y_train, forward_prop(alpha_minus, X_train))\n",
    "    denominator = 2 * epsilon\n",
    "\n",
    "    # Calculate Grad-appox\n",
    "    d_alpha_appox = np.mean(numerator / denominator) * 2\n",
    "\n",
    "    # Beta\n",
    "\n",
    "    # + epsilon on the beta term\n",
    "    beta_plus = W + ep_beta\n",
    "    beta_minus = W - ep_beta\n",
    "\n",
    "    # Forward Prop\n",
    "    numerator = cost(y_train, forward_prop(beta_plus, X_train)) - cost(y_train, forward_prop(beta_minus, X_train))\n",
    "    denominator = 2 * epsilon\n",
    "\n",
    "    # Calculate Grad-appox\n",
    "    d_beta_appox = np.mean(numerator / denominator) * 2\n",
    "\n",
    "    # Gamma\n",
    "\n",
    "    # + epsilon on the gamma term\n",
    "    gamma_plus = W + ep_gamma\n",
    "    gamma_minus = W - ep_gamma\n",
    "\n",
    "    # Forward Prop\n",
    "    numerator = cost(y_train, forward_prop(gamma_plus, X_train)) - cost(y_train, forward_prop(gamma_minus, X_train))\n",
    "    denominator = 2 * epsilon\n",
    "\n",
    "    # Calculate Grad-appox\n",
    "    d_gamma_appox = np.mean(numerator / denominator) * 2\n",
    "\n",
    "    # Delta\n",
    "\n",
    "    # + epsilon on the delta term\n",
    "    delta_plus = W + ep_delta\n",
    "    delta_minus = W - ep_delta\n",
    "\n",
    "    # Forward Prop\n",
    "    numerator = cost(y_train, forward_prop(delta_plus, X_train)) - cost(y_train, forward_prop(delta_minus, X_train))\n",
    "    denominator = 2 * epsilon\n",
    "\n",
    "    # Calculate Grad-appox\n",
    "    d_delta_appox = np.mean(numerator / denominator) * 2\n",
    "\n",
    "    # Put all the numerical gradient into a matrix\n",
    "    grad_appox = np.array([[d_alpha_appox, d_beta_appox], [d_gamma_appox, d_delta_appox ]])\n",
    "\n",
    "    assert np.round(np.linalg.norm(grad_appox - grad * -2), 7) == 0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After implementing grad check, it is found that the current 'back_prop' method generates a gradient matrix that is a factor of -2 away from the grad check value. \n",
    "\n",
    "The L2 norm between 'grad' (function) and 'grad_appox' (numerical) is zero, when round to 7 decimal places for 10_000 random examples. \n",
    "\n",
    "This suggests a certain correctness to the implementation of both system.\n",
    "\n",
    "It is more likely that the problem lies in the 'back_prop' function since there is inherently more calculation in that step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 6. Gradient Descent\n",
    "\n",
    "The code for this is simple enough to just be inspect by eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 11: Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that everything is checked, the training can start. Implement the code by the following order\n",
    "\n",
    "    1. Create train/test data (X_train, y_train, X_test, y_test)\n",
    "    2. Initialize weights (W)\n",
    "    \n",
    "    Loop\n",
    "    \n",
    "    3. Forward Propagation (y_hat)\n",
    "    4. Define Cost Function (L)\n",
    "    5. Back Propagation (grad) * -2\n",
    "    6. Gradient Descent (W)\n",
    "    \n",
    "    Finally\n",
    "    \n",
    "    7. Normalized the matrix\n",
    "    \n",
    "The dataset is created before the model is trained\n",
    "The input of the 'train' method are\n",
    "    1. X-values\n",
    "    2. y-values\n",
    "    3. Weight initialization type ( = None ('random') )\n",
    "    4. Number of iterations (= 50)\n",
    "    5. Learning rate (= 0.1)\n",
    "    6. Loss / mse print frequency ( = 10)\n",
    "    7. Random seed ( = 0)\n",
    "    8. Print weights ( = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, init_weights = 'random', iterations = 50, \n",
    "          learning_rate = 0.1, print_frequency = 10, seed = 0, print_weights = True):\n",
    "    \n",
    "    \"\"\"\n",
    "    Train model from (X, y) pairs\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ndarray\n",
    "        X-values for training\n",
    "    y: ndarray\n",
    "        y-values for the corresponding X-values\n",
    "    init_weights: str\n",
    "        'random' or 'zeros'\n",
    "    iterations: int\n",
    "        Number of weights updates through forward / backpropagation\n",
    "    learning_rate: float\n",
    "        Step size for weights update\n",
    "    print_frequency: int\n",
    "        Loss / mse print frequency\n",
    "    seed: int\n",
    "        Used for pseudo-randomly generate matrix\n",
    "    print_weights: bool\n",
    "        Show weights at the end for visual comparison\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    W: ndarray\n",
    "        Final weights after training\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Weights initialization\n",
    "    if type(init_weights) == str:\n",
    "        W = initialize(init_type = init_weights, seed = 0)\n",
    "    else:\n",
    "        W = init_weights\n",
    "\n",
    "    print('Training: \\n')\n",
    "    \n",
    "    for i in range(iterations):\n",
    "\n",
    "        # Foward Propagation\n",
    "        y_hat = forward_prop(W, X)\n",
    "\n",
    "        # Compute cost\n",
    "        L = cost(y, y_hat)\n",
    "        \n",
    "        # Compute mse\n",
    "        mse = cost(W, M_correct)\n",
    "\n",
    "        # Print loss and mse\n",
    "        if i % print_frequency == 0:\n",
    "            print(f'{i}th iteration, loss = {np.round(L, 6)}, mse = {np.round(mse, 6)}')\n",
    "\n",
    "        # Backpropagation\n",
    "        grad = back_prop(y, y_hat, X) * -2 # Multiply by a factor of -2 from above\n",
    "        \n",
    "        # Gradient Descent (The bigger the learning rate, the faster the model trains <= 1)\n",
    "        W = gradient_descent(W, grad, learning_rate = learning_rate) \n",
    "        \n",
    "    # Normalized W matrix\n",
    "    \n",
    "    W /= np.linalg.norm(W, axis = 0)\n",
    "        \n",
    "    # Print weights\n",
    "    if print_weights:\n",
    "        print('\\n')\n",
    "        print('Final Weights')\n",
    "        view(W)\n",
    "        print('\\n')\n",
    "        \n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 12: Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the weights of the created test set. The metrics here is 'mse'.\n",
    "\n",
    "The parameters for this functions are:\n",
    "\n",
    "    1. Trained weights\n",
    "    2. X-values test set\n",
    "    3. y-values test set\n",
    "\n",
    "The function will return a 'mse' metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(trained_weights, X, y):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test model from (X, y) pairs\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trained_weights: ndarray\n",
    "        Weights from previously trained model\n",
    "    X: ndarray\n",
    "        X-values for testing\n",
    "    y: ndarray\n",
    "        y-values for the corresponding X-values\n",
    "        \n",
    "    \"\"\"\n",
    "    print('Evaluation: \\n')\n",
    "    \n",
    "    # Foward Propagation\n",
    "    y_hat = forward_prop(trained_weights, X)\n",
    "        \n",
    "    # Compute mse\n",
    "    mse = cost(y, y_hat)\n",
    "\n",
    "    print(f'mse = {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 13: Full Optimization Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Matrix:\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.707106781186547 & 0.707106781186547\\\\0.707106781186547 & -0.707106781186547\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[0.707106781186547,  0.707106781186547],\n",
       "[0.707106781186547, -0.707106781186547]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training: \n",
      "\n",
      "0th iteration, loss = 0.349286, mse = 0.400872\n",
      "20th iteration, loss = 0.024185, mse = 0.027757\n",
      "40th iteration, loss = 0.001675, mse = 0.001922\n",
      "60th iteration, loss = 0.000116, mse = 0.000133\n",
      "80th iteration, loss = 8e-06, mse = 9e-06\n",
      "\n",
      "\n",
      "Final Weights\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}0.707072740664112 & 0.707902073187454\\\\0.707140820070332 & -0.706310593702873\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[0.707072740664112,  0.707902073187454],\n",
       "[0.707140820070332, -0.706310593702873]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Evaluation: \n",
      "\n",
      "mse = 3.8293921714689e-07\n"
     ]
    }
   ],
   "source": [
    "# Define correct matrix\n",
    "M_correct = H\n",
    "\n",
    "print('Correct Matrix:')\n",
    "view(M_correct)\n",
    "print('\\n')\n",
    "\n",
    "# Create data\n",
    "X_train, y_train, X_test, y_test = create_data(M_correct, size = 5)\n",
    "\n",
    "# Train model\n",
    "model_weights = train(X_train, y_train, init_weights = 'random', iterations = 100, learning_rate = 1, print_frequency=20)\n",
    "\n",
    "# Evaluate model\n",
    "predict(model_weights, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 14: Sampling on Quantum Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sample qubits on a quantum circuit, the weights has to a in the form of a unitary matrix. \n",
    "\n",
    "This can be acheived by applying the Gram-Schmidt process to the matrix. The resulting orthonormal matrix is unitary in real numbers.\n",
    "\n",
    "To create an orthonormal basis for the set of vectors $\\{v_1, v_2\\}$,\n",
    "$$u_1 = \\frac{v_1}{||v_1||}\\$$\n",
    "\n",
    "$$y_2 = v_2 - (v_2 \\cdot u_1) \\ u_1$$\n",
    "\n",
    "$$u_2 = \\frac{y_2}{||y_2||}$$\n",
    "\n",
    "At the end, we have\n",
    "\n",
    "$$\\{v_1, v_2\\} \\longrightarrow \\{u_1, u_2\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gram-Schmidt for 2D real vector sets\n",
    "\n",
    "def gs_2d_real(M):\n",
    "    \n",
    "    # Split into individual components\n",
    "    v1 = M[:, 0].reshape(2, 1)\n",
    "    v2 = M[:, 1].reshape(2, 1)\n",
    "\n",
    "    # Normalize\n",
    "    u1 = v1 / np.linalg.norm(v1)\n",
    "\n",
    "    # Calculate orthogonal vector\n",
    "    y2 = v2 - np.dot(v2.T, u1) * u1\n",
    "\n",
    "    # Normalize\n",
    "    u2 = y2 / np.linalg.norm(y2)\n",
    "\n",
    "    # Put back to a matrix\n",
    "    ortho_M = np.hstack((u1, u2))\n",
    "\n",
    "    # Check for unitary\n",
    "    assert np.round(np.sum(np.dot(ortho_M, ortho_M.conj().T)), 10) == 2, 'ortho_M is not unitary'\n",
    "    \n",
    "    return ortho_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the weights as unitary matrix, we can feed it into the circuit to sample qubits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 387.452x204.68 with 1 Axes>"
      ]
     },
     "execution_count": 1203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Orthonormalize the weights\n",
    "U = gs_2d_real(model_weights)\n",
    "\n",
    "# Initialize Quantum Circuit\n",
    "circ = QuantumCircuit(2, 2)\n",
    "\n",
    "# Apply weights matrix as unitary gate\n",
    "circ.unitary(U, 0)\n",
    "\n",
    "# Apply CX\n",
    "circ.cx(0, 1)\n",
    "\n",
    "# Measure\n",
    "circ.measure([0, 1], [0, 1])\n",
    "\n",
    "# Draw Circuit\n",
    "circ.draw('mpl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "execution_count": 1204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulator = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "# For Mathematical Representation\n",
    "results = execute(circ, simulator).result()\n",
    "\n",
    "# Count Results\n",
    "counts = results.get_counts(circ)\n",
    "\n",
    "# Plot Histogram\n",
    "plot_histogram(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
